{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Pose Graph Optimization (scratch + g2o)\n",
    "TEAM-ID: 20    \n",
    "TEAM-NAME: formula-ai\n",
    "YOUR-ID: 2018122003\n",
    "YOUR-NAME: Krishna Kumar Maram\n",
    "\n",
    "(Although you work in groups, both the students have to submit to Moodle, hence there's name field above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission\n",
    "Zip a folder of the following:\n",
    "1. Files that you were provided with: `Project-1.ipynb`, the folders `misc` and `dataset`. Rest of the files asked in the questions below must be generated when i run the code. If generation of any file is computationally intensive, add `filename_backup.extension` where `filename.extension` is the expected name of file when i run the code. (For example, next point.)\n",
    "2. Add `opt_backup.g2o` (described below) in outermost directory. Here, `opt.g2o` is the expected name of the file when I run the code.\n",
    "3. For images of any results (like plots), save it in `./misc` folder.\n",
    "\n",
    "On Moodle, all you have to submit is the jupyter notebook. But make sure to call the necessary functions explicitly (as specified in the notebook). The name of the zipped file being submitted to Moodle Assignment portal MUST BE `ID_Teamname_Firstname`. More details [here](https://www.notion.so/saishubodh/Course-Information-4c9e487b118547b2ba91d24e0dcaf04e#f2707a04f2a0446bac77763b47ba4bac).\n",
    "\n",
    "On GitHub classrooms, the latest commit before the deadline will be considered as the submission. \n",
    "\n",
    "The deadline is Oct 16, 23:55 IST. Please get started ASAP, there is no way you can finish this project during the last few days before the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General instructions\n",
    "\n",
    "This ipython notebook (`.ipynb`) on GitHub is self-sufficient and has all the information you need to get started with the assignment, you don't need any corresponding PDF doc. Just fire up the notebook and get going!\n",
    "\n",
    "General information like installation instructions in supplementary notebook \"Project-1_Code-Walkthrough\". Please take a look at it before you start this assignment.\n",
    "\n",
    "Whenever I mention some `func()` below, I am referring to the \"helper functions\" in another supplementary notebook \"Project-1_Code-Walkthrough\" provided to you. Whenever I ask you to insert image below, it is better to save the image in `misc` and load it using `![file_name](file_location)` instead of directly pasting.    \n",
    "\n",
    "[[CP-]] refers to CheckPoint, you have to ensure you do the tasks at each of the [[CP-]] places below. Not ensuring [[CP-B]] (CheckPoint-Basic) will incur heavy penalty and potentially 0 for that sub-section, and [[CP-M]] (CheckPoint-Marks) has a particular mark weightage depending on your results at that particular CP.\n",
    "\n",
    "If you face any issues related to coding/installation, please raise an [issue here](https://github.com/Shubodh/MR-project1-pgo/issues). For any conceptual doubts, you can ask on Moodle or Teams as usual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction\n",
    "\n",
    "In this project, we are going to use a non-linear weighted least squares optimization approach to solve the problem of getting a better estimate of our robot's trajectory. Least squares formulations are widely used for optimization, be it computer vision or robotics or machine learning. We will dive deep into it during this project and you will have complete clarity on optimization for vector-valued residual functions. \n",
    "\n",
    "In this \"Introduction\" section, I am going to provide an introduction for SLAM problem for a robot operating in the 2D world. It is 2. section in this Project. The 1D SLAM problem (1.) is far much simpler to understand and will be described directly in the 1. section. \n",
    "\n",
    "In a 2D world, a robot has 3 degrees of freedom, i.e. its pose in the world can be expressed by the state vector $\\mathbf{x}=(x, y, \\theta)^{\\mathrm{T}}$. For the scope of this project, we are interested only in the robot's trajectory through the $2 \\mathrm{D}$ world, and NOT in distinct landmarks or the surronding map of the environment, i.e. we are only interested in \"L\"ocalization part of SLAM. \n",
    "\n",
    "Therefore, we can represent it as a graph where the vertices represent robot poses $\\mathbf{x}_{i}$ and edges represent the spatial constraints between these poses. Such a map is generally called a pose graph.\n",
    "\n",
    "Two different kinds of constraints are necessary for pose graph SLAM. The first are\n",
    "odometric constraints that connect two successive states $\\mathbf{x}_{i}$ and $\\mathbf{x}_{i+1}$ via a motion model. Furthermore, in order to perform loop closing, the robot has to recognize places it already visited before. This place recognition is also a part of the front-end and provides the second type of constraint, the loop closure constraints. These constraints connect two not necessarily successive poses $\\mathbf{x}_{i}$ and $\\mathbf{x}_{j}$.\n",
    "\n",
    "\n",
    "![SLAM-trajectory-lc.png](misc/SLAM-trajectory-lc.png)   ![SLAM-trajectory-robust.png](misc/SLAM-trajectory-robust.png) (Source: [Sunderhauf 2012](https://core.ac.uk/download/pdf/89299995.pdf))\n",
    "\n",
    "You will start from the inaccurate pose graph with odometry and loop closure information and by the end of this Project, you end up with an optimized pose graph (see above images) which should look close to ground truth trajectory. You can watch [this video](https://youtu.be/saVZtgPyyJQ) to get an intuition for what we're about to do.\n",
    "\n",
    "Okay, that's enough of theory. Let's get out hands dirty with the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import jax\n",
    "import jax.numpy as jnp #see supplementary notebook to see how to use this\n",
    "from jax import jacfwd\n",
    "import numpy as np\n",
    "\n",
    "# If you're `importing numpy as np` for debugging purposes, \n",
    "# while submitting, please remove 'import numpy' and replace all np's with jnp's.(more in supplementary notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pose Graph Optimization for 1D SLAM\n",
    "\n",
    "A solved example for 1D SLAM which optimizes for pose variables using weighted least squares method (Gauss Newton) has been explained in the class. It has been made [available here](https://www.notion.so/saishubodh/Solved-Example-1D-SLAM-weighted-LS-Illustrating-Sparsity-in-SLAM-d8b45893843b4377b07b1d4aa1aab4de). Your first task is to code this from scratch. [[CP-M]]\n",
    "\n",
    "For this section, you have to calculate Jacobian analytically yourself and use it. However, you can check how correct `jax`'s `jacobian`. Its usage is explained in the supplementary notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/anaconda3/envs/mr_assignment1/lib/python3.7/site-packages/jax/lib/xla_bridge.py:130: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "# TODO: Code for Section 1\n",
    "def motionModel(x,u):\n",
    "    return x+u\n",
    "\n",
    "def infoMat(x1):\n",
    "    return jnp.linalg.inv(jnp.cov(x))\n",
    "\n",
    "def residual(x,u):\n",
    "    x_list=list(x)\n",
    "    x_list2=x_list[:-1]+[x_list[0]]\n",
    "    x_list3=x_list[1:]+[x_list[4]] + [0]\n",
    "    x_mod1=jnp.array(x_list2)\n",
    "    x_mod2=jnp.array(x_list3)\n",
    "    est=motionModel(x_mod1,u)\n",
    "    xListEst=list(est)\n",
    "    x_list4=xListEst+[x_list[0]]\n",
    "    x_modEst=jnp.array(x_list4)\n",
    "    \n",
    "    return x_modEst-x_mod2\n",
    "\n",
    "#residual calculation\n",
    "f=lambda x_r: residual(x_r,uob)\n",
    "\n",
    "#Confidence Matrix with assumed \n",
    "cov=jnp.dot(0.01,\n",
    "          jnp.identity(6))\n",
    "cov=jax.ops.index_update(cov,jax.ops.index[5,5],0.001)\n",
    "omega=jnp.linalg.inv(cov)\n",
    "\n",
    "\n",
    "#Objective Function\n",
    "F=lambda x: jnp.dot(\n",
    "  jnp.dot(jnp.transpose(f(x)),omega),\n",
    "  f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussNewton(k_p,learningRate,tolerance,maxIterations):\n",
    "    alpha=learningRate #learning rate\n",
    "    max_iterations=maxIterations\n",
    "    tolerance=tolerance\n",
    "    res_vec=f(k_p)\n",
    "    r_val=jnp.dot(jnp.transpose(res_vec),res_vec)\n",
    "    del_r=jnp.array([[1.0,-1.0,0.0,0.0,0.0],\n",
    "                   [0.0,1.0,-1.0,0.0,0.0],\n",
    "                   [0.0,0.0,1.0,-1.0,0.0],\n",
    "                   [0.0,0.0,0.0,1.0,-1.0],\n",
    "                   [1.0,0.0,0.0,0.0,-1.0],\n",
    "                   [1.0,0.0,0.0,0.0,0.0]])\n",
    "    \n",
    "    #jacobian calculation\n",
    "#     j=jacfwd(f)\n",
    "#     print(j(k_p))\n",
    "    \n",
    "    #Hessian matrix calucalation\n",
    "    H=jnp.dot(\n",
    "        jnp.dot(jnp.transpose(del_r),omega),\n",
    "        del_r)\n",
    "#     print(H)\n",
    "        \n",
    "    def direction():\n",
    "        \n",
    "        term1=jnp.linalg.inv(H)\n",
    "        term2=-jnp.dot(\n",
    "            jnp.dot(jnp.transpose(del_r),jnp.transpose(omega)),\n",
    "            f(k_p))\n",
    "        term3=jnp.dot(term1,term2)\n",
    "        return term3\n",
    "    \n",
    "    \n",
    "    k_p=k_p+alpha*direction()\n",
    "    \n",
    "    itr=0\n",
    "    while(itr<maxIterations and r_val>=tolerance):\n",
    "        k_p=k_p+alpha*direction()\n",
    "        if(itr==0):\n",
    "            print('Estimate after first iteration of Gauss Newton=',k_p)\n",
    "        if(itr==3):\n",
    "            print('Estimate afte second iteration of Gauss Newton=',k_p)\n",
    "        res_vec=f(k_p)\n",
    "        r_val=jnp.dot(jnp.transpose(res_vec),res_vec)\n",
    "        itr+=1  \n",
    "    return k_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate after first iteration of Gauss Newton= [-3.5762282e-10  1.0000000e+00  1.9000000e+00  2.9000001e+00\n",
      "  1.0000000e-01]\n",
      "Estimate afte second iteration of Gauss Newton= [-3.2782785e-10  1.0000000e+00  1.9000000e+00  2.9000001e+00\n",
      "  1.0000000e-01]\n",
      "The estimate after optimization= [-3.2782707e-10  1.0000000e+00  1.9000000e+00  2.9000001e+00\n",
      "  1.0000000e-01]\n"
     ]
    }
   ],
   "source": [
    "#Ground Truth\n",
    "ugt=jnp.array([1,1,1,-3.0])\n",
    "xgt=jnp.array([0,1,2,3,0])\n",
    "\n",
    "#Observed values \n",
    "uob=jnp.array([1.1,1.0,1.1,-2.7,0.0])\n",
    "xob=jnp.array([0.0,1.1,2.1,3.2,0.5])\n",
    "\n",
    "#initial residual\n",
    "# print(F(xob))\n",
    "\n",
    "#Optimization using Gauss Newton\n",
    "alpha=1\n",
    "tol=10^-5\n",
    "maxIterations=200\n",
    "x_opt=gaussNewton(xob,alpha,tol,maxIterations) #Estimate\n",
    "print('The estimate after optimization=',x_opt)\n",
    "# print(F(x_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pose Graph Optimization for 2D SLAM\n",
    "\n",
    "Things are about to get interesting!\n",
    "\n",
    "## 2.1 Coding from scratch\n",
    "\n",
    "### Objective\n",
    "A robot is travelling in a oval trajectory. It is equipped with wheel odometry for odometry information and RGBD sensors for loop closure information. Due to noise in wheel odometry it generates a noisy estimate of the trajectory. Our task is to use loop closure pairs to correct the drift.\n",
    "\n",
    "We pose this problem as a graph optimization problem. In our graph, poses are the vertices and constraints are the edges. \n",
    "\n",
    "### Given: \n",
    "In practical scenarios, we'd obtain the following from our sensors after some post-processing:\n",
    "1. Initial position\n",
    "2. Odometry Contraints/Edges: This \"edge\" information basically tells us relative transformation between two nodes. These two nodes are consecutive in the case of Odometry but not in the case of Loop Closure (next point).\n",
    "3. Loop Closure Contraints/Edges\n",
    "Remember that while optimizing, you have another kind of \"anchor\" edge as you've seen in 1. solved example.\n",
    "\n",
    "You have been given a text file named `edges.txt` which has all the above 3 and it follows G2O's format (as explained in class, [link here](https://www.notion.so/saishubodh/G2O-Edge-Description-fa07cc28967541dc8a71170de46c5da7) )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details:\n",
    "1. Using the following motion model, you have to first generate the \"initialization\" for all the poses/vertices using the \"Given\" information. Just like in the 1D case.\n",
    "$$x_{k+1} = x_{k} + \\Delta x_{(k,k+1)} \\cos(\\theta_k) - \\Delta y_{(k,k+1)} \\sin(\\theta_k) \\\\\n",
    "y_{k+1} = y_{k} + \\Delta y_{(k,k+1)} \\cos(\\theta_k) + \\Delta x_{(k,k+1)} \\sin(\\theta_k) \\\\\n",
    "\\theta_{k+1} = \\theta_{k}+  \\Delta \\theta_{(k,k+1)} \\tag{3}$$\n",
    "\n",
    "Even the loop closure nodes are related by the above model, except that it need not necessarily be consecutive notes k and k+1.\n",
    "\n",
    "Save this initial trajectory as `edges-poses.g2o`.\n",
    "\n",
    "If you plot the initialized poses using odometry information, you need to get as the right plot [[CP-M]] below (this is the \"noisy trajectory\"): (Left one is the ground truth)\n",
    "![robot-poses-MR-P1.png](./misc/robot-poses-MR-P1.png)\n",
    "(Use `draw()` helper function or `g2o_viewer` or `EVO`)\n",
    "\n",
    "2. Now calculate the residual and the Jacobian and update your parameters using LM.\n",
    "\n",
    "Use LM algorithm. Regarding Jacobian calculation, you can use `jax`'s `jacobian` as part of your main code. However, you still have to separately calculate it analytically and verify if it matches with `jax`'s `jacobian` using [[CP-M]] frobenius norm `frobNorm()`). Calculation and verification is compulsory, but it is your choice to use whichever as part of your optimization. Use whichever is faster.\n",
    "\n",
    "3. Regarding LM iterations, stopping criterion, information matrix values.\n",
    "\n",
    "    1. [[CP-B]] As your iterations proceed, you have to print relevant information (iteration number and error value: [$F = \\frac{1}{2}  \\mathbf{f}^{\\top} \\mathbf{\\Omega} \\mathbf{f} $ (notion page link)](https://www.notion.so/saishubodh/From-linear-algebra-to-non-linear-weighted-least-squares-optimization-13cf17d318be4d45bb8577c4d3ea4a02#32832dee7d6c4ab49581463d9b784f21) at every step).\n",
    "    \n",
    "    2. [[CP-B]] You have to show the plots (ground truth, noisy & optimized: all 3 in a single plot) at every 10 steps or so.\n",
    "\n",
    "    3. [[CP-M]] You could start with information values of 500 for odom edges, 700 for loop closure edges, 1000 for anchor edge (same for all dimensions). However, you have to _heavily_ experiment with these values. (Given that you somehow know loop closure information is way more reliable than odometry.). At the end of your experimentation, your error $F = \\frac{1}{2}  \\mathbf{f}^{\\top} \\mathbf{\\Omega} \\mathbf{f} $ should by < 40. Explain your experimentation in detail using tables/plots etc if necessary.\n",
    "    \n",
    "Do not worry if you're not getting a perfect trajectory. Our parametrization was oversimplified for the sake of this project. With that being said, it is possible to get the error down to < 40 and make it at least look like an oval shaped trajectory, even if it doesn't perfectly resemble the ground truth. However, using `g2o` (next section), you will be getting a close to ground truth trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readVertex(fileName):\n",
    "    f = open(fileName, 'r')\n",
    "    A = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "    x_arr = []\n",
    "    y_arr = []\n",
    "    theta_arr = []\n",
    "\n",
    "    for line in A:\n",
    "        if \"VERTEX_SE2\" in line:\n",
    "            (ver, ind, x, y, theta) = line.split()\n",
    "            x_arr.append(float(x))\n",
    "            y_arr.append(float(y))\n",
    "            theta_arr.append(float(theta.rstrip('\\n')))\n",
    "\n",
    "    return jnp.array([x_arr, y_arr, theta_arr])\n",
    "\n",
    "def readEdge(fileName):\n",
    "    f = open(fileName, 'r')\n",
    "    A = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "    ind1_arr = []\n",
    "    ind2_arr = []\n",
    "    del_x = []\n",
    "    del_y = []\n",
    "    del_theta = []\n",
    "\n",
    "    for line in A:\n",
    "        if \"EDGE_SE2\" in line:\n",
    "            (edge, ind1, ind2, dx, dy, dtheta, _, _, _, _, _, _) = line.split()\n",
    "            ind1_arr.append(int(ind1))\n",
    "            ind2_arr.append(int(ind2))\n",
    "            del_x.append(float(dx))\n",
    "            del_y.append(float(dy))\n",
    "            del_theta.append(float(dtheta))\n",
    "\n",
    "    return (jnp.array( ind1_arr), jnp.array(ind2_arr), jnp.array(del_x), jnp.array(del_y), jnp.array(del_theta))\n",
    "def draw(X, Y, THETA):\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(X, Y, 'ro')\n",
    "    plt.plot(X, Y, 'c-')\n",
    "\n",
    "    for i in range(len(THETA)):\n",
    "        x2 = 0.25*math.cos(THETA[i]) + X[i]\n",
    "        y2 = 0.25*math.sin(THETA[i]) + Y[i]\n",
    "        plt.plot([X[i], x2], [Y[i], y2], 'b->')\n",
    "\n",
    "    plt.show()\n",
    "def draw3(X1, Y1, THETA1, X2,Y2,THETA2,X3,Y3,THETA3,save=False,name='result'):\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(X1, Y1, 'bo',label='Ground Truth')\n",
    "    plt.plot(X1, Y1, 'k-')\n",
    "\n",
    "    for i in range(len(THETA1)):\n",
    "        x2 = 0.25*math.cos(THETA1[i]) + X1[i]\n",
    "        y2 = 0.25*math.sin(THETA1[i]) + Y1[i]\n",
    "        plt.plot([X1[i], x2], [Y1[i], y2], 'b->')\n",
    "    \n",
    "    ax.plot(X2, Y2, 'go',label='Init')\n",
    "    plt.plot(X2, Y2, 'k-')\n",
    "\n",
    "    for i in range(len(THETA2)):\n",
    "        x2 = 0.25*math.cos(THETA2[i]) + X2[i]\n",
    "        y2 = 0.25*math.sin(THETA2[i]) + Y2[i]\n",
    "        plt.plot([X2[i], x2], [Y2[i], y2], 'g->')\n",
    "    \n",
    "    ax.plot(X3, Y3, 'mo',label='Optimized')\n",
    "    plt.plot(X3, Y3, 'k-')\n",
    "\n",
    "    for i in range(len(THETA3)):\n",
    "        x2 = 0.25*math.cos(THETA3[i]) + X3[i]\n",
    "        y2 = 0.25*math.sin(THETA3[i]) + Y3[i]\n",
    "        plt.plot([X3[i], x2], [Y3[i], y2], 'm->')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    if save==True:\n",
    "        plt.savefig('plot_'+name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Code for Section 2.1                                                 #\n",
    "file = open('dataset/edges.txt',\"r\")\n",
    "data = file.readlines()\n",
    "index_i,index_j,del_x,del_y,del_theta = readEdge('dataset/edges.txt')\n",
    "vertices = readVertex('dataset/edges.txt')\n",
    "gt_vertices = readVertex('dataset/gt.txt')\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "position = [vertices]\n",
    "for c in range(index_i.shape[0]):\n",
    "    i,j = index_i[c],index_j[c]\n",
    "    if i+1 != j:\n",
    "        break\n",
    "    old_x,old_y,old_theta = position[i]\n",
    "    diff = jnp.array([del_x[i],del_y[i]]).reshape(2,1)\n",
    "    old = jnp.array([old_x,old_y]).reshape(2,1)\n",
    "    angles = jnp.array([[jnp.cos(old_theta),-jnp.sin(old_theta)],[jnp.sin(old_theta),jnp.cos(old_theta)]]).reshape(2,2)\n",
    "    new = old + angles@diff\n",
    "    new_x,new_y = new\n",
    "    new_theta = old_theta + del_theta[i]\n",
    "    new_pos = jnp.array([new_x,new_y,new_theta])\n",
    "    position.append(new_pos)\n",
    "pos = jnp.array(position)\n",
    "init_X,init_Y,init_THETA = pos[:,0],pos[:,1],pos[:,2]\n",
    "gt_X,gt_Y,gt_THETA = gt_vertices\n",
    "draw(init_X,init_Y,init_THETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vertex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-93d67968f947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'VERTEX'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mvertex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'EDGE'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0medges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vertex' is not defined"
     ]
    }
   ],
   "source": [
    "edges = []\n",
    "for d in data:\n",
    "    if 'VERTEX' in d:\n",
    "        vertex.append(d)\n",
    "    if 'EDGE' in d:\n",
    "        edges.append(d)\n",
    "edges.append('FIX 0\\n')\n",
    "def write_vertex(position):\n",
    "    vertex = []\n",
    "    for i,pos in enumerate(position):\n",
    "        x,y,theta = pos\n",
    "        n_vertex = []\n",
    "        n_vertex.append('VERTEX_SE2')\n",
    "        n_vertex.append(str(i+1))\n",
    "        n_vertex.append(str(x[0]))\n",
    "        n_vertex.append(str(y[0]))\n",
    "        n_vertex.append(str(theta[0]))\n",
    "        vertex_string = \" \".join(n_vertex)\n",
    "        vertex_string+= '\\n'\n",
    "        vertex.append(vertex_string)\n",
    "    return vertex\n",
    "vert = write_vertex(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('edges-poses.g2o','w') as filehandle:\n",
    "    filehandle.writelines(\"%s\" % v for v in vert)\n",
    "    filehandle.writelines(\"%s\" % e for e in edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pos_x(old_x,del_x,del_y,old_theta):\n",
    "    return old_x+del_x*jnp.cos(old_theta) - del_y*jnp.sin(old_theta)\n",
    "def calc_pos_y(old_y,del_x,del_y,old_theta):\n",
    "    return old_y+del_y*jnp.cos(old_theta) + del_x*jnp.sin(old_theta)\n",
    "def calc_pos_theta(old_theta,del_theta):\n",
    "    return old_theta+del_theta\n",
    "orig_x,orig_y,orig_theta = vertices\n",
    "def residual(Vec,index_i,index_j,del_x,del_y,del_theta):\n",
    "    X,Y,THETA = Vec[:,0],Vec[:,1],Vec[:,2]\n",
    "    f = []\n",
    "    for ind in range(index_i.shape[0]):\n",
    "        i,j = index_i[ind],index_j[ind]\n",
    "        x_col = calc_pos_x(X[i],del_x[i],del_y[i],THETA[i]) - X[j]\n",
    "        y_col = calc_pos_y(Y[i],del_x[i],del_y[i],THETA[i]) - Y[j]\n",
    "        theta_col = calc_pos_theta(THETA[i],del_theta[i]) - THETA[j]\n",
    "        col = jnp.array([x_col,y_col,theta_col])\n",
    "        f.append(col)\n",
    "    col = jnp.array([X[0]-orig_x,Y[0]-orig_y,THETA[0]-orig_theta])\n",
    "    f.append(col)\n",
    "    f = jnp.array(f).flatten('F')\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_info(odometry,loop,fixed):\n",
    "    information = []\n",
    "    for ind in range(index_i.shape[0]):\n",
    "        i,j = index_i[ind],index_j[ind]\n",
    "        if i+1 == j:\n",
    "            information.append(odometry)\n",
    "        else:\n",
    "            information.append(loop)\n",
    "    information.append(fixed)\n",
    "    information = information*3\n",
    "    info = jnp.array(information)\n",
    "    info_matrix = jnp.diag(info)\n",
    "    return info_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_=lambda vector : residual(vector,index_i,index_j,del_x,del_y,del_theta)\n",
    "def total_error(residual,info_matrix):\n",
    "    return 0.5*residual.T@info_matrix@residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x w.r.t everything\n",
    "from jax.ops import index, index_add, index_update\n",
    "def manual_jacobian(X,Y,THETA):\n",
    "    x_deriv = []\n",
    "    for ind in range(index_i.shape[0]):\n",
    "        i,j = index_i[ind],index_j[ind]\n",
    "        deriv_x = jnp.zeros([360])\n",
    "        deriv_x = index_update(deriv_x,index[i],1)\n",
    "        deriv_x = index_update(deriv_x,index[j],-1)\n",
    "        theta_update = -del_x[i]*jnp.sin(THETA[i]) - del_y[i]*jnp.cos(THETA[i])\n",
    "        deriv_x = index_update(deriv_x,index[240+i],float(theta_update))\n",
    "        x_deriv.append(deriv_x)\n",
    "    deriv_x = jnp.zeros([360])\n",
    "    deriv_x = index_update(deriv_x,index[0],1)\n",
    "    x_deriv.append(deriv_x)\n",
    "    x_deriv = jnp.array(x_deriv)\n",
    "\n",
    "    #y w.r.t everything\n",
    "    y_deriv = []\n",
    "    for ind in range(index_i.shape[0]):\n",
    "        i,j = index_i[ind],index_j[ind]\n",
    "        deriv_y = jnp.zeros([360])\n",
    "        deriv_y = index_update(deriv_y,index[120+i],1)\n",
    "        deriv_y = index_update(deriv_y,index[120+j],-1)\n",
    "        theta_update = -del_y[i]*jnp.sin(THETA[i]) + del_x[i]*jnp.cos(THETA[i])\n",
    "        deriv_y = index_update(deriv_y,index[240+i],float(theta_update))\n",
    "        y_deriv.append(deriv_y)\n",
    "    deriv_y = jnp.zeros([360])\n",
    "    deriv_y = index_update(deriv_y,index[120],1)\n",
    "    y_deriv.append(deriv_y)\n",
    "    y_deriv = jnp.array(y_deriv)\n",
    "\n",
    "    #theta w.r.t everything\n",
    "    theta_deriv = []\n",
    "    for ind in range(index_i.shape[0]):\n",
    "        i,j = index_i[ind],index_j[ind]\n",
    "        deriv_theta = jnp.zeros([360])\n",
    "        deriv_theta = index_update(deriv_theta,index[240+i],1)\n",
    "        deriv_theta = index_update(deriv_theta,index[240+j],-1)\n",
    "        theta_deriv.append(deriv_theta)\n",
    "    deriv_theta = jnp.zeros([360])\n",
    "    deriv_theta = index_update(deriv_theta,index[240],1)\n",
    "    theta_deriv.append(deriv_theta)\n",
    "    theta_deriv = jnp.array(theta_deriv)\n",
    "\n",
    "    #concatinating them together\n",
    "    m_j = jnp.vstack((x_deriv,y_deriv,theta_deriv))\n",
    "    return m_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_jacobian(f_,posi):\n",
    "    j=jacfwd(f_)\n",
    "    jacobian = j(posi)\n",
    "    k = []\n",
    "    for i in range(420):\n",
    "        k.append(jacobian[i].flatten('F'))\n",
    "    jac = jnp.array(k)\n",
    "    return jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_pos = jnp.array(position)\n",
    "m_jac = manual_jacobian(inp_pos[:,1],inp_pos[:,2],inp_pos[:,3])\n",
    "jac = cal_jacobian(f_,inp_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frobNorm(P1, P2, str1=\"mat1\", str2=\"mat2\"):\n",
    "    jnp.set_printoptions(suppress=True)\n",
    "    val = jnp.linalg.norm(P1 - P2, 'fro')\n",
    "    print(f\"Frobenius norm between {str1} and {str2} is: {val}\")\n",
    "frobNorm(jac,m_jac,\"Jax Jacobian\",\"Manual Jacobian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direction(jac,info_matrix,residual):\n",
    "    H = jac.T@info_matrix@jac\n",
    "    b = jac.T@info_matrix.T@residual\n",
    "    update_vec = jnp.linalg.inv(H)@b\n",
    "    return update_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_poses(pos,name):\n",
    "    n_vert = write_vertex(pos)\n",
    "    n_vert.append('FIX 0\\n')\n",
    "    with open(name+'.g2o','w') as filehandle:\n",
    "        filehandle.writelines(\"%s\" % v for v in n_vert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(X,Y,THETA,info_matrix,save=False,name='result'):\n",
    "    errors = []\n",
    "    for i in range(30):\n",
    "        position_matrix = jnp.hstack([X,Y,THETA]).reshape(120,3,1)\n",
    "        residual_vector = f_(position_matrix)\n",
    "        jac = cal_jacobian(f_,position_matrix)\n",
    "        error = total_error(residual_vector,info_matrix)\n",
    "        errors.append(error)\n",
    "        print(\"Iteration : %d, Error : %f\" % (i,float(error)))\n",
    "        if i%5 == 0:\n",
    "            draw3(gt_X,gt_Y,gt_THETA,init_X,init_Y,init_THETA,X,Y,THETA)\n",
    "        if error < 40:\n",
    "            break\n",
    "        update_vec = direction(jac,info_matrix,residual_vector)\n",
    "        X -= update_vec[:120].reshape(120,1)\n",
    "        Y -= update_vec[120:240].reshape(120,1)\n",
    "        THETA -= update_vec[240:360].reshape(120,1)\n",
    "    if save:\n",
    "        draw3(gt_X,gt_Y,gt_THETA,init_X,init_Y,init_THETA,X,Y,THETA,save,name)\n",
    "    else:\n",
    "        draw3(gt_X,gt_Y,gt_THETA,init_X,init_Y,init_THETA,X,Y,THETA)\n",
    "    new_pos = np.hstack([X,Y,THETA]).reshape(120,3,1)\n",
    "    return new_pos,errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_matrix = create_info(500.0,700.0,1000.0)\n",
    "new_pos,e = optimize(init_X,init_Y,init_THETA,info_matrix)\n",
    "save_poses(new_pos,'opt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_matrix = create_info(100.0,1000.0,1000.0)\n",
    "new_pos,e = optimize(init_X,init_Y,init_THETA,info_matrix)\n",
    "save_poses(new_pos,'opt_100_1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_matrix = create_info(10.0,1000.0,1000.0)\n",
    "new_pos,e = optimize(init_X,init_Y,init_THETA,info_matrix)\n",
    "save_poses(new_pos,'opt_10_1000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Answer\n",
    "\n",
    "Give a detailed answer addressing the above questions. When I run the above code, it should follow points described above (such as plots at every 10 steps) and (When I run the above code, it should) write the optimized poses to a file named `opt.g2o`. As a backup, save another file `opt_backup.g2o` in an offline manner beforehand.\n",
    "\n",
    "That apart, save important plots and add them here so that it can supplement your answer, for example you could add plots at crucial stages of optimization. You have to add useful metrics/plots from `EVO` (refer to supplementary notebook). Using EVO, the bare minimum you have to report is `mean absolute pose error (ape)` and `mean relative pose error (rpe)`. However, you are encouraged to use tools like `evo_traj` and [more](https://github.com/MichaelGrupp/evo/#command-line-interface) and add more plots/metrics. Marks will be awarded based on overall analysis & presentation which would reflect your understanding.\n",
    "\n",
    "Note that `EVO` and `g2o_viewer` (below) could help you in debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "We observe that error was governed by the confidence we had in odometry constraints. Reducing it had significant impact on overall error. However, we are not able to get a better map in any case which can be highlighted by plots from EVO\n",
    "1) Odometry - 500, Loop - 700  \n",
    "RPE\n",
    "![](misc/rpe.png)  \n",
    "APE\n",
    "![](misc/ape.png)  \n",
    "XYZ losses  \n",
    "![](misc/trajec_xyz.png)\n",
    "Rotation Diff\n",
    "![](misc/trajec_rpy.png)\n",
    "2) Odometry - 100, Loop - 1000  \n",
    "RPE\n",
    "![](misc/rpe_1000.png)  \n",
    "APE\n",
    "![](misc/ape_100.png)  \n",
    "XYZ losses  \n",
    "![](misc/trajec_xyz_100.png)\n",
    "Rotation Diff\n",
    "![](misc/trajec_rpy_100.png)\n",
    "3) Odometry - 10, Loop - 1000  \n",
    "RPE\n",
    "![](misc/rpe_10.png)  \n",
    "APE\n",
    "![](misc/ape_10.png)  \n",
    "XYZ losses  \n",
    "![](misc/trajec_xyz_10.png)\n",
    "Rotation Diff\n",
    "![](misc/trajec_rpy_10.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Using g2o's optimization: g2o binary or g2o viewer \n",
    "\n",
    "Installation setup is described in supplementary notebook. More details for 2.2.1 and 2.2.2 can be found in the supplementary notebook.\n",
    "\n",
    "### 2.2.1 Optimizing `edges.txt`\n",
    "First task is to optimize the poses of dataset you've been working with so far.\n",
    "\n",
    "### 2.2.2 Optimizing `intel` and `sphere` datasets\n",
    "You have been given two datasets in the `data` folder. You have to use `g2o_viewer` to optimize these both. You have to experiment with the options/parameters available in the GUI. More instructions in supplementary notebook. You have to experiment till you get the trajectories which look like the following:\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"./misc/intel.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "<td> <img src=\"./misc/sphere.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Answer\n",
    "\n",
    "Add images: take screenshot of the GUI of `g2o_viewer` after optimization for all 3 [[CP-M]] and add here. Briefly describe what you had to do (detailed answer is not expected). g2o could potentially give you close to ground truth trajectory for all 3, but if you are unable to get to close to ground truth, add the best you can get.\n",
    "\n",
    "#### Optimization of Edges.\n",
    "\n",
    "(i) Generated the poses for edges.g20. \n",
    "\n",
    "(ii). Loaded edges.g2o on g2o and optimized it for 50 itertaions. \n",
    "Using gn_var_cholmod.using spanning tree.  \n",
    "\n",
    "(iii) Experimented with other optimizers, but gave the same result.\n",
    "\n",
    "\n",
    "<img src=\"./misc/edges.png\"/> \n",
    "\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization of Intel.g2o\n",
    "\n",
    "(i) Optimzed for 50 iterations. \n",
    "\n",
    "(ii) Optimized using gn_var_cholmod\n",
    "<img src=\"./misc/Intel.png\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization of shere.g2o\n",
    "\n",
    "1. First experimented without using robust kernel. Obtained a curvature at top, could not optimize further. \n",
    "\n",
    "2. Then optimized using **robust kernel(fair)** **with kernel width 0.2.** Did not get a curvature, and the number of iterations were just 100.\n",
    "\n",
    "4. Increased the number of iterations.\n",
    "<img src=\"./misc/sphere_opt_final.png\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  * Important Information regarding Questions 3  & 4\n",
    "Note that it is mandatory to attempt EITHER 3 OR 4, only one of it. If you attempt both, the question which you score more will be considered and the other as bonus question. \n",
    "\n",
    "It is encouraged for those into robotics/deep learning research to prefer 4 over 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Bonus*] 3. Deriving Motion model geometrically\n",
    "\\* -> read information above under section \"Important Information regarding Questions 3  & 4\"\n",
    "\n",
    " \n",
    "The current robot state is as follows: ($i$ and $k$ are interchangably used below, sorry I am too lazy to edit now )  \n",
    "![robot-situation.png](./misc/robot-situation.png)\n",
    "\n",
    "Can you derive the below equation using geometry? (Read on)\n",
    "\n",
    "$$x_{k+1} = x_{k} + \\Delta x_{(k,k+1)} \\cos(\\theta_k) - \\Delta y_{(k,k+1)} \\sin(\\theta_k) \\\\\n",
    "y_{k+1} = y_{k} + \\Delta y_{(k,k+1)} \\cos(\\theta_k) + \\Delta x_{(k,k+1)} \\sin(\\theta_k) \\\\\n",
    "\\theta_{k+1} = \\theta_{k}+  \\Delta \\theta_{(k,k+1)} \\tag{3}$$\n",
    "\n",
    "In other words, we want to find $\\delta$'s in terms of $\\Delta$'s\n",
    "$$\\delta x = \\Delta x \\cos(\\theta) - \\Delta y \\sin(\\theta) \\\\\n",
    "\\delta y = \\Delta y \\cos(\\theta) + \\Delta x \\sin(\\theta) \\tag{2}$$\n",
    "\n",
    "where $\\delta$'s are the updates in our motion model equation:\n",
    "$$ x_{k+1} = x_{k} + \\delta x \\\\\n",
    "y_{k + 1} = y_k + \\delta y \\\\\n",
    "\\theta_{k+1} = \\theta_{k} + \\delta \\theta \\tag{1}$$\n",
    "\n",
    "Oh yes, $\\theta$ is straightforward, i.e. $\\delta \\theta = \\Delta \\theta$ but why? \n",
    "\n",
    "Using geometry, you could just draw and insert a self-explanatory image as the answer to this question.\n",
    "\n",
    "If you can derive it without using geometry purely using transform matrices/algebra, that is fine too. Whatever you're comfortable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Answer\n",
    "\n",
    "\n",
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Bonus*] 4. Research Paper Reading\n",
    "\\* -> read information above under section \"Important Information regarding Questions 3  & 4\"\n",
    "\n",
    "(Do not get intimidated, you are not expected to do a thorough research analysis for this task. A high level understanding is sufficient.)\n",
    "\n",
    "\n",
    "[\"Past, Present & Future of SLAM: Towards the Robust Perception Age\"](https://arxiv.org/abs/1606.05830) is an exciting survey paper of 2016 which sums up, well, the \"past, present & future\" of SLAM. Your task is as follows:\n",
    "\n",
    "1. Go through the sections \"IV. LONG-TERM AUTONOMY II: SCALABILITY\" & \"III. LONG-TERM AUTONOMY I: ROBUSTNESS\". Don't worry, you are not expected to have a deep understanding. Skip the parts which you don't understand at all. Go through it at a high level, and take a slightly closer look at \"Open Problems\" in these sections.\n",
    "\n",
    "2. Read up common applications of deep learning for computer vision/robotics through blogs online (for example, first 4 points of [this](https://machinelearningmastery.com/applications-of-deep-learning-for-computer-vision/). Again, you are only expected to understand it at a high level, for example, 'semantic segmentation is an application of deep learning for computer vision which is the task of assigning a category to each of the pixels in the image'.\n",
    "\n",
    "Firstly, summarize your understanding of the above two points.\n",
    "   \n",
    "Now, from the understanding you've gathered so far, how would you approach solving those \"Open Problems\"? \n",
    "Can these algorithms help in dealing with some of the issues you might have faced during this project? Can the deep learing based high level understanding of the world help in SLAM? In the context of long term autonomy, imagine tomorrow's world with a buddy robot R2-D2 which follows you wherever you go... Now imagine how easily the trajectory can diverge, how big the map could soon become and how the computation could easily become intractable.   \n",
    "\n",
    "Answer the above questions in the context of this project and those 2 sections of the survey paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Answer\n",
    "\n",
    "1.\n",
    "### Summary of Past, Present & Future of SLAM: Towards the Robust Perception Age.\n",
    "#### Section-IV:Long-Term Autonomy I: Robustess\n",
    "Failure of a SLAM system can occur either at algorithmic level or at hardware level. The main source of algorithmic errors are the errors occuring during Data association process. The problems that occur during data association are the presence of outliers or false positives. The SLAM system has to deal with challenging environments with limited visibility and constantly changing environment. Other data association problems are related to perceptual aliasing. There are problems associated with short term and long term changes in the environment for SLAM system. SLAM systems designed with the assumption of static environment can only work in small scale environment.\n",
    "\n",
    "Short term data association is easy to track with camera having sufficient frame rate. Standard procedures like descriptor matching or optical flow can track feautres between consequetive images despite the changes in the environmnet the front end can track and perform short term data associations. Long term data-association involves loop closures detection and validation. The bruteforce approach to loop closure is computationaly intensive as the current image is checked for matching with every other image in the dataset.Bag of words technique quantizes the feature spae and allows more efficient search. Bag of words can give a reliable performance on single precision loop closure but they fail when there are severe illumination variation. This leads to unified representation by using matching sequences and using visual as well as spatial appereances. hese methods reason on the validity of loop closure constraints by looking at the residual error induced by the constraints during optimization. Other methods,instead, attempt to detect outliers a priori, that is, before any optimization takes place, by identifying incorrect loop closures that are not supported by the odometry. The problems associated with robustness can be addressed in the front end or backend of the SLAM system. Some algorithms keep track of changes incured in the dynamic envronment, while main stream techniques do not. Current systems to deal with these problems either maintain multiple maps or have a single representation parameterized by some time-varying parameter.\n",
    "\n",
    "###### Open Problmes\n",
    "Current systems are still vulnerable to outliers and regenracies. SLAM systems should have recovery mechanisms to restablish proper operation. A solution to this approach is tighter integration between front end and back end systems of SLAM. \n",
    "\n",
    "Malfunctioning of sensor nodes lead to degradation in accuracy. Off-nominal conditions, or aging or if the quality of the sensors do match with noise models used in the back end it will lead to poor estimates. The problem now becomes to resolve the conflicting readings from different sensors. And it is crucial to resolve these problems in saftey-critical applications. \n",
    "\n",
    "The current SLAM systems and data association methods(descriptors) or not equipped to work reliably under conditions of day and night \n",
    "sequences or between different seasons for metric relocation. Current feature descriptors do not have sufficient invariance to work to work reliably in such circumstances.Spatial\n",
    "information, inherent to the SLAM problem, such as trajectory\n",
    "matching, might be exploited to overcome these limitations.\n",
    "Additionally, mapping with one sensor modality (e.g., 3D\n",
    "lidar) and localizing in the same map with a different sensor\n",
    "modality (e.g., camera) can be a useful addition.\n",
    "\n",
    "SLAM systems are developed only for static and rigid world. Although in the computer vision community and recent non-rigid SFM are able to produce all terrain maps but they are restrictive in thier capabilities. Addressing case of non-rigidity is still a problem which is unexplored. \n",
    "\n",
    "SLAM systems need humann input for assigning thresholds that control feature matching RANSAC parameters. But if the SLAM has to work in all kinds of arbitary scenarios, methods of automatic tuning of the invloved parameters needs to be considered. \n",
    "\n",
    "#### Section-IV:Long-Term Autonomy II:Scalability\n",
    "\n",
    "For such applications the size of the\n",
    "factor graph underlying SLAM can grow unbounded, due to\n",
    "the continuous exploration of new places and the increasing\n",
    "time of operation. \n",
    "\n",
    "This family of methods addresses scalability by reducing the number of nodes added to the graph, or by including less informative nodes and factors. Use an information-theoretic approach.To add only non-redundant nodes and highly-informative measurements to the graph. \n",
    "\n",
    "Another line of work that allows reducing the number of pa-\n",
    "rameters to be estimated over time is the continuous-time tra-\n",
    "jectory estimation. the nodes in the factor graph represented the control-points (knots) of the spline which were optimized in a sliding window fashion. This idea has been further improved and optimized by a lot of people, and they are were able to extend it to large scale applications. \n",
    "\n",
    "Parallel out-of-core algorithms for SLAM split the computation (and memory) load of factor graph optimization among multiple processors. The key idea is to divide the factor graph into different subgraphs and optimize the overall graph by alternating local optimization of each subgraph, with a global refinement. \n",
    "\n",
    "Distributed multi robot SLAM: One way of mapping a large-scale environment is to deploy multiple robots doing SLAM, and divide the scenario in smaller areas, each one mapped by a different robot. This approach has two main variants: the centralized one, where robots build submaps and transfer the local information to a central station that performs inference, and the decentralized one, where there is no central data fusion and the agents leverage local communication to reach consensus on a common map. \n",
    "\n",
    "The disadvantage of the using popluar method of Gaussian elemination is that the marginals to be exchanged among the robots are large sized and the communication cost is quadratic in the number of seperators. An alternate approach to Gaussian elimination method is Gauss-Sidel approach which implies a communication burden which is linear in the number of seperators. \n",
    "\n",
    "\n",
    "#### Open problems\n",
    "Despite the work done to reduce the complexity of the factor graph optimization, there have been a lot of aspcets which have been unexplored. \n",
    "For example Storage of map/point cloud data or volumetric maps in the memory for extended period of time. While other questions upon which adequete work has not been done are 'How long should a map be remembered or be in the storage?', When should a map be updated and when is a map or data considered to be outdated?. \n",
    "Another opend ended problem is rejection of outliers in a distributed robot system. The problems with multi robot system are that they do not share a common frame of reference and they have to detect outliers using partial and local information. Some of the attempts that were made were to timely check and verify the thier location and their prediction of the trajectory at probably at a specified location(rendezvous strategy) before fusing information.\n",
    "Another problem is to adapt SLAM algorithms in places where severe computational resource constraints exist. This can be seen where the size of the plaotform is scaled down, for example in Mobile phones, micro areial vehicles or robotic insects. Other problems that can arise due to hardwareAnother constraints is the limited bandwidth and communication dropout. And so it would be desirable to have algorithms in which one can tune accuracy with computational load. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing and Ideating about the Open Problems,\n",
    "There are a lot of open problems to ideate and think about , keeping the two broad sections in mind - Scalability and Robustness. Let's explore some of the open problems these domains\n",
    "\n",
    "### Scalability\n",
    "1. What to learn and what to forget - The open problem is to see how often to update the mapping information. The problem in some level analogous to what caches are meant to do. If an efficient to identify necessary , commonly needed info and only store that while generating other info on demand. \n",
    "2. Map representation - During long term mapping , large amount of data is generated. Advanced data compression techniques can help in this to store this data efficiently.\n",
    "### Robusteness \n",
    "1. Slam Recovery - We have established that incorrect measurements are bound to creep up due to localisation problem , we need to have a robust fraud detection system (can use temporal features - previous set of images) to identify whether the input is a valid input or not and reject those below a certaing confidence threshold.\n",
    "2. Non Dynamic Mapping - The real world is constantly evolving and changing , thus systems to address these are needed. This will require identifying things in a constantly changing environment. A very interesting use case for the same is described in this [paper](https://arxiv.org/abs/1705.05444) which aims to visualise 3d mapping of internal organs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following paper represents the map implicitly in a deep convolutional neural network (by training on a proper map i.e. images/views with 6 degree-of-freedom camera pose), and can regress the pose of a novel camera image captured in the same environment. So it can do localization, but would need additional machinery to extend the map. To my surprise, it can capture fairly large scale maps.\n",
    "\n",
    "http://arxiv.org/pdf/1505.07427.pdf\n",
    "\n",
    "The following paper learns to do visual odometry with a deep CNN given a couple of nearby frames. Although it doesn't work very well yet, but one can imagine hooking this (perhaps trained with a lot more data?) into something like the LSD-SLAM pipeline to obtain much more robust associations between neighboring frames or a frame with its nearest keyframe, than edges alone can provide.\n",
    "\n",
    "http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Agrawal_Learning_to_See_ICCV_2015_paper.pdf\n",
    "\n",
    "One might also wonder whether there is even a need for explicitly doing SLAM in many applications. For instance, the following latest work by DeepMind is obviously able to understand the environment and navigate within it, without needing any explicit SLAM module. Rather it just learns to navigate in the virtual environment, using a deep reinforcement learning objective. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some interesting insights\n",
    "    Training on a scene-heavy dataset, such as Places by MIT CSAIL, or the Google Street View dataset, improves place recognition performance quite a bit compared to object-heavy sets.\n",
    "\n",
    "    End-to-end training for place recognition handily beats using pre-trained models focused on classification. It seems that medium-depth representation are quite important here.\n",
    "\n",
    "    A feed-forward pass through a CNN is much faster than using hand-engineered features, even on a CPU. Interesting speedups for existing SLAM systems seems within easy reach, with the caveat that they need both feature-level and image-level descriptors at the same time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun section\n",
    "Check the end of your Project-1 homepage on Notion. :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
